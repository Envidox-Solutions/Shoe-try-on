<!DOCTYPE html>
<html>
<head>
  <title>Body Tracking AR with A-Frame</title>
  <script src="https://aframe.io/releases/1.2.0/aframe.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/posenet"></script>
</head>
<body>
  <a-scene embedded arjs>
    <!-- Camera to access user's camera feed -->
    <a-entity camera></a-entity>

    <!-- Virtual shoe model -->
    <a-gltf-model
      id="shoeModel"
      src="path/to/your/virtual_shoe_model.gltf"
      scale="0.1 0.1 0.1"
      position="0 0 0"
    ></a-gltf-model>

    <script>
      // Function to align virtual shoes with the user's feet
      function alignVirtualShoesWithFeet(keypoints) {
        const leftFoot = keypoints[15];
        const rightFoot = keypoints[16];

        // If feet keypoints are not detected, hide the virtual shoes
        if (!leftFoot || !rightFoot) {
          document.getElementById("shoeModel").setAttribute("visible", "false");
          return;
        }

        const leftFootPosition = leftFoot.position;
        const rightFootPosition = rightFoot.position;

        // Average the positions of both feet
        const avgFootPosition = {
          x: (leftFootPosition.x + rightFootPosition.x) / 2,
          y: (leftFootPosition.y + rightFootPosition.y) / 2,
          z: (leftFootPosition.z + rightFootPosition.z) / 2,
        };

        // Set the virtual shoe's position to the average foot position
        document
          .getElementById("shoeModel")
          .setAttribute("position", `${avgFootPosition.x} ${avgFootPosition.y} ${avgFootPosition.z}`);
        
        // Make the virtual shoes visible
        document.getElementById("shoeModel").setAttribute("visible", "true");
      }

      // Function to perform body tracking using PoseNet
      async function trackBody() {
        const video = document.querySelector("video");
        const net = await posenet.load();

        // Continuously track the body in the camera feed
        setInterval(async () => {
          const pose = await net.estimateSinglePose(video, {
            flipHorizontal: false,
          });

          // Call the alignment function with detected keypoints
          alignVirtualShoesWithFeet(pose.keypoints);
        }, 100); // Adjust the interval as needed
      }

      // Start body tracking when the scene is loaded
      document.querySelector("a-scene").addEventListener("loaded", () => {
        // Start the camera
        const camera = document.querySelector("[camera]");
        camera.components["device-orientation-permission-ui"].askPermission();
        camera.components.camera.getMediaStream().then((stream) => {
          const video = document.createElement("video");
          video.setAttribute("autoplay", "true");
          video.setAttribute("muted", "true");
          video.srcObject = stream;
          video.addEventListener("loadeddata", () => {
            video.play();

            // Call the function to start body tracking
            trackBody();
          });
        });
      });
    </script>
  </a-scene>
</body>
</html>
